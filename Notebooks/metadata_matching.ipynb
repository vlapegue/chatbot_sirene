{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189448c-229f-4fd5-b1d0-995e57e72434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prérequis : Installer les modules présents dans le notebook recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb64d2-68e6-45f1-b703-67e2497e9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e880e3e-c8bf-48df-b932-673ff8f0437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser les embeddings d'HuggingFace\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c59ece-6f20-40c4-a770-231b3503b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les embeddings d'une question et des metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0aa86-6c1a-4791-b249-25fa0400cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"bdconsignes.txt\")\n",
    "pages_txt=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d3e3a7-82f4-4a72-9592-ab6b13439c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb02dbc-8e0e-45d2-a007-ba92c9255bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bed86-36fe-44e9-ad23-a83c658120cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits = markdown_splitter.split_text(pages_txt[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b41827-213b-4a93-bbca-e8a7ec499de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_docs=[]\n",
    "for i in range(len(md_header_splits)):\n",
    "    metadata_inter=\"\"\n",
    "    if any(item in list(md_header_splits[i].metadata.keys()) for item in ['Header 2','Header 3']) is False:\n",
    "        metadata_inter=metadata_inter+md_header_splits[i].metadata['Header 1']\n",
    "    if 'Header 2' in list(md_header_splits[i].metadata.keys()):\n",
    "        metadata_inter=metadata_inter+md_header_splits[i].metadata['Header 2']\n",
    "    if 'Header 3' in list(md_header_splits[i].metadata.keys()):\n",
    "        metadata_inter=metadata_inter+'. '+md_header_splits[i].metadata['Header 3']\n",
    "    metadata_docs.append(metadata_inter)\n",
    "embeddings_metadata = model.encode(metadata_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47bb8a-0c87-4826-9d2a-c513c652156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tout est rassemblé dans une fonction\n",
    "def met_match_txt(question, embeddings_metadata,k):\n",
    "    query_embedding = model.encode(question)\n",
    "    similarity_scores = cosine_similarity(query_embedding.reshape(1,-1), embeddings_metadata)\n",
    "    # Sort the documents based on similarity scores\n",
    "    sorted_indices = np.argsort(similarity_scores)[0]\n",
    "    sorted_documents = [md_header_splits[i].page_content for i in sorted_indices][::-1]\n",
    "    sorted_documents=sorted_documents[:k]\n",
    "    top_k_documents=\"\"\n",
    "    for i in range(k):\n",
    "        top_k_documents=top_k_documents+'\\n\\n'+sorted_documents[i]\n",
    "    return top_k_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0337e3-5016-418a-9c1e-a1db50c03e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tout est rassemblé dans une fonction\n",
    "def met_match_doc(question, embeddings_metadata,k):\n",
    "    query_embedding = model.encode(question)\n",
    "    similarity_scores = cosine_similarity(query_embedding.reshape(1,-1), embeddings_metadata)\n",
    "    # Sort the documents based on similarity scores\n",
    "    sorted_indices = np.argsort(similarity_scores)[0]\n",
    "    sorted_documents = [md_header_splits[i] for i in sorted_indices][::-1]\n",
    "    top_k_documents=sorted_documents[:k]\n",
    "    return top_k_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d34a44-6047-4c60-9474-9231bd484561",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_match_txt(embeddings_metadata=embeddings_metadata,k=2,question=\"comment changer d'APE ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11e67c-a94e-4c20-801f-06a3307c565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_match_doc(embeddings_metadata=embeddings_metadata,k=2,question=\"comment changer d'APE ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea483899-cf92-4b63-892e-f3d0ab7becf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e2078-29c5-4e29-be54-038726f0e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c518f-2052-484d-95a4-32eb7fc32438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée un prompt template, on initialise le modèle et l'output parser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "import streamlit as st\n",
    "# Build prompt llama chat\n",
    "template_chat = \"\"\"<s>[INST] <<SYS>>\n",
    "\\n\n",
    "Vous êtes un assistant conversationnel concis et honnête, qui répond, uniquement en langue française, aux problèmes posés par un usager. Si vous ne connaissez pas la réponse, répondez simplement que vous ne savez pas, n'essayez pas d'inventer la réponse.  \n",
    "\\n<</SYS>>\n",
    "\\n\n",
    "À l'aide du contexte ci-dessous, répondez, uniquement en langue française, au problème suivant posé par un usager : \"{question}\". Si besoin, demandez à l'usager certaines informations afin de préciser votre réponse en fonction du contexte.\n",
    "\\n\\n\n",
    "Contexte : \n",
    "\\n\n",
    "{context}\n",
    "[/INST]\"\"\"\n",
    "QA_CHAIN_PROMPT_chat = PromptTemplate.from_template(template_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55399fbe-d810-481a-a049-f96411862a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    # Verbose is required to pass to the callback manager\n",
    "n_batch = 512\n",
    "llm = LlamaCpp(\n",
    "    model_path='./llama-2-7b-chat.Q5_K_M.gguf',\n",
    "    n_gpu_layers=0,\n",
    "    max_tokens = 8000,\n",
    "    temperature = 0.0,\n",
    "    n_batch=n_batch,\n",
    "    f16_kv=True,\n",
    "    use_mlock=True,\n",
    "    n_ctx=2048,\n",
    "    callback_manager=callback_manager,\n",
    "    n_threads=8,\n",
    "    verbose=True,\n",
    "    streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737670f-8b87-4f94-994b-33e2ccb215f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: met_match_txt(embeddings_metadata=embeddings_metadata,k=2,question=x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}) | QA_CHAIN_PROMPT_chat | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea18484-be9d-4142-8b0e-4c647fdcb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "# On utilise config-callbacks pour avoir le détail du déroulement de la chaîne\n",
    "chain.invoke({\"question\": \"Comment changer d'APE?\"},config={'callbacks': [ConsoleCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3889d-75e0-4d65-9acc-fd6cd5e528b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a09b7-9b24-4df4-8446-365378191753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de la mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5e88e-af4b-4383-b7aa-dbeee9f77736",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=RunnableMap({\n",
    "    \"context\": lambda x: met_match_txt(embeddings_metadata=embeddings_metadata,k=2,question=x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]}).invoke({\"question\": \"Où puis-je obtenir mon avis de situation ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94144dfe-40e5-4ff0-b5aa-603b46de009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test))\n",
    "print(test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ae998-5142-4ec3-b4cc-4b5253817938",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_memory=PromptTemplate(input_variables=['chat_history', 'question','context'],\n",
    "               template='''<s>[INST] <<SYS>>\n",
    "\\n\n",
    "Vous êtes un assistant conversationnel cordial et honnête, qui répond, \n",
    "               uniquement en langue française, aux questions ou aux problèmes posés par un usager. \n",
    "               Si vous ne connaissez pas la réponse, répondez simplement que vous ne savez pas, \n",
    "               n'essayez pas d'inventer la réponse.\n",
    "               \\n<</SYS>>\\n\n",
    "               Historique de la conversation:\\n{chat_history}\n",
    "               \\n À l'aide de l'historique de la conversation ci-dessus, et du contexte ci-dessous, répondez, \n",
    "               uniquement en langue française, au problème suivant posé par un usager : {question}\\n\n",
    "               [/INST]''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d730197-2973-4d4c-b3bf-f2d5936cbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On garde en mémoire l'historique des messages\n",
    "# Return_messages = True signifie qu'on met les messages passés sous forme de liste, \n",
    "# et non de la forme d'un simple texte\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f99bd-d451-4fa4-987c-50ab928af959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom retriever à l'aide de la fonction met_match\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "from langchain.schema import Document\n",
    "from typing import List\n",
    "\n",
    "class CustomRetriever(BaseRetriever):\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        # Use your existing retriever to get the documents\n",
    "        documents = met_match_doc(embeddings_metadata=embeddings_metadata,k=2,question=query)\n",
    "        \n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80675024-b7b3-493a-9e3a-9f1866ac54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le module ConversationalRetrievalChain gère la mémoire\n",
    "\n",
    "qa_memory = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=CustomRetriever(),\n",
    "    memory=memory,\n",
    "    condense_question_prompt=template_memory,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df3ebd-614a-4524-b6c9-4390566d12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_chain=RunnableMap({\n",
    "    \"context\": lambda x: met_match_txt(embeddings_metadata=embeddings_metadata,k=2,question=x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]}) | qa_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d34799-2c0b-46ce-a0df-452af1cc6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Où puis-je obtenir mon avis de situation ?\"\n",
    "result = memory_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd01e6-9ec4-4127-be69-1d9f2c553bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Où puis-je obtenir mon avis de situation ?\"\n",
    "result = qa_memory.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37363b-bf56-44a1-8f33-50dd4b987a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le prompt est en anglais, on le change\n",
    "qa_memory_promptfr = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=CustomRetriever(),\n",
    "    memory=memory,\n",
    "    condense_question_prompt=template_memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": QA_CHAIN_PROMPT_chat},\n",
    "    verbose=True)\n",
    "#,\n",
    "#    combine_docs_chain_kwargs={\"prompt\": QA_CHAIN_PROMPT_chat}\n",
    "# combine_docs_chain_kwargs={\n",
    "        #\"prompt\": ChatPromptTemplate.from_messages([\n",
    "            #system_message_prompt,\n",
    "            #human_message_prompt,\n",
    "        #]),\n",
    "    #}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3db12a-f5cc-4244-bddc-4215a34e5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_chain_promptfr=RunnableMap({\n",
    "    \"context\": lambda x: met_match_txt(embeddings_metadata=embeddings_metadata,k=2,question=x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]}) | qa_memory_promptfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29823e-66fa-4089-b5cd-ad952f167e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59abff-7aab-4054-bb46-a1c9030eff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Où puis-je obtenir mon avis de situation ?\"\n",
    "result = qa_memory_promptfr.invoke({\"question\": question,'context': 'Test_contexte'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b02b8-9b81-4b00-9e61-eda0526c198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Je ne sais pas si mes données sont diffusées\"\n",
    "result = memory_chain_promptfr.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b57c0c-bf48-4de9-b70c-89ff829252c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e51ad2-98b4-4860-8252-66ef8ff60f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Je ne sais pas si mes données sont diffusées\"\n",
    "result = qa_memory({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45cfbd-fb3b-4a7f-9035-e59b9962a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48614775-ebe9-4ad7-b618-80f05e25a798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c128c15-c0a5-4694-81c6-aab914555428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89872e09-8358-430a-886a-6500df2ed55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555bf01-36f5-4d17-821d-55d103d7b7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caeffd2-a3ca-489f-85e8-b18a5fce86b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad998c6-b75d-4193-ad42-170443173389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d9db8-cc08-41f2-b20b-231b3ba36a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ac670-4ce4-421d-9318-e2d0b6fb0cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cfa3e-3b98-4d12-b2be-e59a100f6e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
