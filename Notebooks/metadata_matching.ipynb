{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189448c-229f-4fd5-b1d0-995e57e72434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prérequis : Installer les modules présents dans le notebook recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e880e3e-c8bf-48df-b932-673ff8f0437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser les embeddings d'HuggingFace\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c59ece-6f20-40c4-a770-231b3503b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les embeddings d'une question et des metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0aa86-6c1a-4791-b249-25fa0400cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"bdconsignes.txt\")\n",
    "pages_txt=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d3e3a7-82f4-4a72-9592-ab6b13439c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb02dbc-8e0e-45d2-a007-ba92c9255bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bed86-36fe-44e9-ad23-a83c658120cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits = markdown_splitter.split_text(pages_txt[0].page_content)\n",
    "# Les metadata sont dans les md_header_splits[i].metadata pour i parcourant l'ensemble des chunks\n",
    "metadata_docs=[]\n",
    "for i in range(len(md_header_splits)):\n",
    "    metadata_inter=\"\"\n",
    "    if any(item in list(md_header_splits[i].metadata.keys()) for item in ['Header 2','Header 3']) is False:\n",
    "        metadata_inter=metadata_inter+md_header_splits[i].metadata['Header 1']\n",
    "    if 'Header 2' in list(md_header_splits[i].metadata.keys()):\n",
    "        metadata_inter=metadata_inter+md_header_splits[i].metadata['Header 2']\n",
    "    if 'Header 3' in list(md_header_splits[i].metadata.keys()):\n",
    "        metadata_inter=metadata_inter+'. '+md_header_splits[i].metadata['Header 3']\n",
    "    metadata_docs.append(metadata_inter)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ba3d6-649a-4c33-b2ae-64d894620dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b41827-213b-4a93-bbca-e8a7ec499de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec99af-e44b-49f2-943a-7055126a51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_metadata = model.encode(metadata_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089a284-17bc-4b1f-89b8-c88eccaa9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings_metadata[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f8696-147a-4e32-b380-91cc9e961969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bdced-1cbc-490c-b86b-0d289b31d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Comment changer d'APE ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc83e5-c21e-4d5e-944d-242811a7e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity between the query embedding and document embeddings\n",
    "query_embedding = model.encode(query)\n",
    "similarity_scores = cosine_similarity(query_embedding.reshape(1,-1), embeddings_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d515632f-c2c5-473e-a35b-04d74307b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fbdbd9-7787-49e8-b772-a002bd3224c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(similarity_scores)[::-1]\n",
    "print(sorted_indices)\n",
    "print(type(sorted_indices))\n",
    "print(type(sorted_indices[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a906c-439f-419e-84c7-3862f71da320",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25476dcf-de9e-4466-95b6-4f72fc8cba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_documents = [md_header_splits[i] for i in sorted_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c791b-b81a-40a3-a435-9686ef6890c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(md_header_splits)):\n",
    "    print(metadata_docs[i])\n",
    "    print(similarity_scores[0][i],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5f0d3-d7f6-406c-8d9f-f15086d9bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(md_header_splits[1].metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c747683-6606-4162-8345-bc6be944e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(md_header_splits[1].metadata['Header 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4037479b-abd1-43a1-9886-571546600ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(md_header_splits)):\n",
    "    if 'Header 3' in list(md_header_splits[i].metadata.keys()):\n",
    "        print(md_header_splits[i].metadata['Header 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5ca02-66c1-48b4-a285-757e974db6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e667c-0a3d-465e-a57b-5766fef7c6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47bb8a-0c87-4826-9d2a-c513c652156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tout est rassemblé dans une fonction\n",
    "def met_match(question, md_header_splits,k):\n",
    "# Les metadata sont dans les md_header_splits[i].metadata pour i parcourant l'ensemble des chunks\n",
    "    metadata_docs=[]\n",
    "    for i in range(len(md_header_splits)):\n",
    "        metadata_inter=\"\"\n",
    "        if any(item in list(md_header_splits[i].metadata.keys()) for item in ['Header 2','Header 3']) is False:\n",
    "            metadata_inter=metadata_inter+md_header_splits[i].metadata['Header 1']\n",
    "        if 'Header 2' in list(md_header_splits[i].metadata.keys()):\n",
    "            metadata_inter=metadata_inter+md_header_splits[i].metadata['Header 2']\n",
    "        if 'Header 3' in list(md_header_splits[i].metadata.keys()):\n",
    "            metadata_inter=metadata_inter+'. '+md_header_splits[i].metadata['Header 3']\n",
    "        metadata_docs.append(metadata_inter)\n",
    "    embeddings_metadata = model.encode(metadata_docs)\n",
    "    query_embedding = model.encode(question)\n",
    "    similarity_scores = cosine_similarity(query_embedding.reshape(1,-1), embeddings_metadata)\n",
    "    # Sort the documents based on similarity scores\n",
    "    sorted_indices = np.argsort(similarity_scores)[0]\n",
    "    sorted_documents = [md_header_splits[i].page_content for i in sorted_indices][::-1]\n",
    "    top_k_documents=\"\"\n",
    "    for i in range(k):\n",
    "        top_k_documents = top_k_documents+'\\n'+sorted_documents[i]\n",
    "    return top_k_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d34a44-6047-4c60-9474-9231bd484561",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_match(md_header_splits=md_header_splits,k=3,question=\"comment changer d'APE ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea483899-cf92-4b63-892e-f3d0ab7becf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e2078-29c5-4e29-be54-038726f0e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c518f-2052-484d-95a4-32eb7fc32438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée un prompt template, on initialise le modèle et l'output parser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "import streamlit as st\n",
    "# Build prompt llama chat\n",
    "template_chat = \"\"\"<s>[INST] <<SYS>>\n",
    "\\n\n",
    "Vous êtes un assistant conversationnel cordial et honnête, qui répond, uniquement en langue française, aux questions ou aux problèmes posés par un usager. Si vous ne connaissez pas la réponse, répondez simplement que vous ne savez pas, n'essayez pas d'inventer la réponse. \n",
    "\\n<</SYS>>\n",
    "\\n\n",
    "À l'aide du contexte ci-dessous, répondez, uniquement en langue française, au problème suivant posé par un usager : {question}\n",
    "\\n\\n\n",
    "Contexte : \n",
    "\\n\n",
    "{context}\n",
    "[/INST]\"\"\"\n",
    "QA_CHAIN_PROMPT_chat = PromptTemplate.from_template(template_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bffdfb-0937-49a0-8da1-6da4d7d96716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55399fbe-d810-481a-a049-f96411862a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    # Verbose is required to pass to the callback manager\n",
    "n_batch = 512\n",
    "llm = LlamaCpp(\n",
    "    model_path='./llama-2-7b-chat.Q5_K_M.gguf',\n",
    "    n_gpu_layers=0,\n",
    "    max_tokens = 8000,\n",
    "    temperature = 0.1,\n",
    "    n_batch=n_batch,\n",
    "    f16_kv=True,\n",
    "    use_mlock=True,\n",
    "    n_ctx=2048,\n",
    "    callback_manager=callback_manager,\n",
    "    n_threads=8,\n",
    "    verbose=True,\n",
    "    streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737670f-8b87-4f94-994b-33e2ccb215f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: met_match(loader=loader,k=2,question=x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}) | QA_CHAIN_PROMPT_chat | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea18484-be9d-4142-8b0e-4c647fdcb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "# On utilise config-callbacks pour avoir le détail du déroulement de la chaîne\n",
    "chain.invoke({\"question\": \"Comment changer d'APE?\"},config={'callbacks': [ConsoleCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3889d-75e0-4d65-9acc-fd6cd5e528b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a09b7-9b24-4df4-8446-365378191753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de la mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ae998-5142-4ec3-b4cc-4b5253817938",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_memory=PromptTemplate(input_variables=['chat_history', 'question'],\n",
    "               template='''<s>[INST] <<SYS>>\n",
    "\\n\n",
    "Vous êtes un assistant conversationnel cordial et honnête, qui répond, \n",
    "               uniquement en langue française, aux questions ou aux problèmes posés par un usager. \n",
    "               Si vous ne connaissez pas la réponse, répondez simplement que vous ne savez pas, \n",
    "               n'essayez pas d'inventer la réponse.\n",
    "               \\n<</SYS>>\\n\n",
    "               Historique de la conversation:\\n{chat_history}\n",
    "               \\n À l'aide de l'historique de la conversation ci-dessus, et du contexte ci-dessous, répondez, \n",
    "               uniquement en langue française, au problème suivant posé par un usager :\n",
    "               \\nSuite de la conversation: {question}\\n[/INST]''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d730197-2973-4d4c-b3bf-f2d5936cbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On garde en mémoire l'historique des messages\n",
    "# Return_messages = True signifie qu'on met les messages passés sous forme de liste, \n",
    "# et non de la forme d'un simple texte\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80675024-b7b3-493a-9e3a-9f1866ac54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le module ConversationalRetrievalChain gère la mémoire\n",
    "\n",
    "retriever=vectordb.as_retriever()\n",
    "qa_memory = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    condense_question_prompt=template_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df3ebd-614a-4524-b6c9-4390566d12a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b57c0c-bf48-4de9-b70c-89ff829252c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e51ad2-98b4-4860-8252-66ef8ff60f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45cfbd-fb3b-4a7f-9035-e59b9962a440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48614775-ebe9-4ad7-b618-80f05e25a798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c128c15-c0a5-4694-81c6-aab914555428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89872e09-8358-430a-886a-6500df2ed55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555bf01-36f5-4d17-821d-55d103d7b7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caeffd2-a3ca-489f-85e8-b18a5fce86b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad998c6-b75d-4193-ad42-170443173389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d9db8-cc08-41f2-b20b-231b3ba36a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ac670-4ce4-421d-9318-e2d0b6fb0cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cfa3e-3b98-4d12-b2be-e59a100f6e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
