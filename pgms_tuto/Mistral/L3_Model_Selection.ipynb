{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get APi Key\n",
    "from helper import load_mistral_api_key\n",
    "api_key, dlai_endpoint = load_mistral_api_key(ret_key=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Note: in the classroom, if you print out this api_key variable, it is not a real API key (for security reasons).\n",
    "    If you wish to run this code on your own machine, outside of the classroom, you can still reuse the code that you see in helper.py.\n",
    "    It uses python-dotenv library to securely save and load sensitive information such as API keys.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "def mistral(user_message, model=\"mistral-small-latest\", is_json=False):\n",
    "    client = MistralClient(api_key=api_key, endpoint=dlai_endpoint)\n",
    "    messages = [ChatMessage(role=\"user\", content=user_message)]\n",
    "\n",
    "    if is_json:\n",
    "        chat_response = client.chat(\n",
    "            model=model, messages=messages, response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "    else:\n",
    "        chat_response = client.chat(model=model, messages=messages)\n",
    "\n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mistral Small\n",
    "\n",
    "Good for simple tasks, fast inference, lower cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "\n",
    "prompt = \"\"\"\n",
    "Classify the following email to determine if it is spam or not.\n",
    "Only respond with the exact text \"Spam\" or \"Not Spam\". \n",
    "\n",
    "# Email:\n",
    "ðŸŽ‰ Urgent! You've Won a $1,000,000 Cash Prize! \n",
    "ðŸ’° To claim your prize, please click on the link below: \n",
    "https://bit.ly/claim-your-prize\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral(prompt, model=\"mistral-small-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mistral Medium\n",
    "\n",
    "Good for intermediate tasks such as language transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composing text based on provided context (e.g. writing a customer service email based on purchase information).\n",
    "\n",
    "prompt = \"\"\"\n",
    "Compose a welcome email for new customers who have just made \n",
    "their first purchase with your product. \n",
    "Start by expressing your gratitude for their business, \n",
    "and then convey your excitement for having them as a customer. \n",
    "Include relevant details about their recent order. \n",
    "Sign the email with \"The Fun Shop Team\".\n",
    "\n",
    "Order details:\n",
    "- Customer name: Anna\n",
    "- Product: hat \n",
    "- Estimate date of delivery: Feb. 25, 2024\n",
    "- Return policy: 30 days\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_medium = mistral(prompt, model=\"mistral-medium-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral Large: \n",
    "\n",
    "Good for complex tasks that require advanced reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math and reasoning with numbers\n",
    "\n",
    "prompt = \"\"\"\n",
    "Calculate the difference in payment dates between the two \\\n",
    "customers whose payment amounts are closest to each other \\\n",
    "in the following dataset. Do not write code.\n",
    "\n",
    "# dataset: \n",
    "'{\n",
    "  \"transaction_id\":{\"0\":\"T1001\",\"1\":\"T1002\",\"2\":\"T1003\",\"3\":\"T1004\",\"4\":\"T1005\"},\n",
    "    \"customer_id\":{\"0\":\"C001\",\"1\":\"C002\",\"2\":\"C003\",\"3\":\"C002\",\"4\":\"C001\"},\n",
    "    \"payment_amount\":{\"0\":125.5,\"1\":89.99,\"2\":120.0,\"3\":54.3,\"4\":210.2},\n",
    "\"payment_date\":{\"0\":\"2021-10-05\",\"1\":\"2021-10-06\",\"2\":\"2021-10-07\",\"3\":\"2021-10-05\",\"4\":\"2021-10-08\"},\n",
    "    \"payment_status\":{\"0\":\"Paid\",\"1\":\"Unpaid\",\"2\":\"Paid\",\"3\":\"Paid\",\"4\":\"Pending\"}\n",
    "}'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_small = mistral(prompt, model=\"mistral-small-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_large = mistral(prompt, model=\"mistral-large-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expense reporting task\n",
    "\n",
    "transactions = \"\"\"\n",
    "McDonald's: 8.40\n",
    "Safeway: 10.30\n",
    "Carrefour: 15.00\n",
    "Toys R Us: 20.50\n",
    "Panda Express: 10.20\n",
    "Beanie Baby Outlet: 25.60\n",
    "World Food Wraps: 22.70\n",
    "Stuffed Animals Shop: 45.10\n",
    "Sanrio Store: 85.70\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Given the purchase details, how much did I spend on each category:\n",
    "1) restaurants\n",
    "2) groceries\n",
    "3) stuffed animals and props\n",
    "{transactions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_small = mistral(prompt, model=\"mistral-small-latest\")\n",
    "print(response_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_large = mistral(prompt, model=\"mistral-large-latest\")\n",
    "print(response_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing and checking code\n",
    "\n",
    "user_message = \"\"\"\n",
    "Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\n",
    "\n",
    "You may assume that each input would have exactly one solution, and you may not use the same element twice.\n",
    "\n",
    "You can return the answer in any order.\n",
    "\n",
    "Your code should pass these tests:\n",
    "\n",
    "assert twoSum([2,7,11,15], 9) == [0,1]\n",
    "assert twoSum([3,2,4], 6) == [1,2]\n",
    "assert twoSum([3,3], 6) == [0,1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mistral(user_message, model=\"mistral-large-latest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natively Fluent in English, French, Spanish, German, and Italian\n",
    "\n",
    "    This means that you can use Mistral models for more than translating from one language to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"\"\"\n",
    "Lequel est le plus lourd une livre de fer ou un kilogramme de plume\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mistral(user_message, model=\"mistral-large-latest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of models :\n",
    "\n",
    "open-mistral-7b\n",
    "open-mixtral-8x7b\n",
    "open-mixtral-8x22b\n",
    "mistral-small-latest\n",
    "mistral-medium-latest\n",
    "mistral-large-latest"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
