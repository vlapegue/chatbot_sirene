{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88157b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging et extraction : un des plus importants cas d'usage des fonctions d'OpenAI\n",
    "# Tagging : Extraire des données structurées d'un texte (non structuré) : \n",
    "# ex : sentiment (positif), langue (espagnol), etc.\n",
    "# Extraction : sortir l'ensemble des informations relatives à un objet défini \n",
    "# ex : Bibliographie de l'ensemble des sources citées dans un article, avec nom des auteurs, date, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453dfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On veut créer une fonction tagging, capable de repérer le sentiment et la langue du texte en input\n",
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On retrouve la structuration JSONtypique des fonctions OpenAI\n",
    "convert_pydantic_to_openai_function(Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fae4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a904673",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be724a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On veut forcer le modèle à tagger les inputs, d'où \"function_call\"\n",
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain.invoke({\"input\": \"I love langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b41e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'output de cette chaîne est un JSON, on va donc mettre en bout de chaîne un maillon qui lit les JSON\n",
    "# et ne récupère que les informations taggées\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b95ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction\n",
    "# Comme le tagging mais on extrait plusieurs informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée une classe permettant de retrouver une personne, avec si possible son âge (en option)\n",
    "from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On veut une liste des classes ci-dessus trouvées dans les textes, c'est cette liste qu'on va transformer en fonction\n",
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f68cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_pydantic_to_openai_function(Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949cdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En résultat ci-dessous, le modèle ne connaît pas l'âge de Martha et gère mal cette ignorance\n",
    "extraction_model.invoke(\"Joe is 30, his mom is Martha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va gérer le comportement du modèle en cas d'ignorance sur l'âge grâce au prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici, l'âge de Martha n'est pas mentionné\n",
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ee598",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df212aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour se débarrasser du nom de la liste (\"people\") on utilise un maillon\n",
    "# qui reconnaît et vire les noms de listes (keys)\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne récupère que les JSON structurés appartenant à la catégorie de la clé prédéfinie dans la chaîne\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d687fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93099d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sur un texte plus long\n",
    "# Exemple : on extrait des infos d'une sous-partie d'un article de blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4660e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe80db",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = doc.page_content[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807afbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le document est long et pas très structuré\n",
    "print(page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b255e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a concise summary of the content.\")\n",
    "    language: str = Field(description=\"Provide the language that the content is written in.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d101c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a83b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a902c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972819c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_extraction_function = [\n",
    "    convert_pydantic_to_openai_function(Info)\n",
    "]\n",
    "extraction_model = model.bind(\n",
    "    functions=paper_extraction_function, \n",
    "    function_call={\"name\":\"Info\"}\n",
    ")\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# résultat ci-dessous décevant : le prompt ne demande pas explicitement de faire une biblio\n",
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On améliore le prompt pour que le modèle fasse réellement une biblio\n",
    "template = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \n",
    "\n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si on part d'un très long article, il faut le séparer en morceaux pour le faire passer dans le LLM\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On découpe en morceaux l'article long\n",
    "splits = text_splitter.split_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47522c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va découper l'article en morceaux, faire l'extraction d'infos dans chaque morceau, et rabouter\n",
    "# La fonction ci-dessous raboutera les différentes listes d'infos extraites\n",
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceaa64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46074ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lorsque le premier maillon de la chaîne est une fonction, il faut utiliser le module ci-dessous\n",
    "# pour convertir la liste de textes en liste d'inputs compatibles avec le prompt\n",
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdf501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing function\n",
    "# La variable d'entrée est le texte entier, qui est découpé, puis mis en forme correctement\n",
    "prep = RunnableLambda(\n",
    "    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e491e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ccd119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilisation de \"map\" pour appliquer la chaîne à une liste d'inputs au bon format\n",
    "# Le mapping est partiellement parallélisé (5 appels en même temps)\n",
    "chain = prep | extraction_chain.map() | flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d1db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b40bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f0013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f631c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aeb4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e267fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
