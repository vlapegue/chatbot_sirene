{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip setuptools wheel\n",
    "#!{sys.executable} -m pip install --disable-pip-version-check torch==1.13.1 torchdata==0.5.1\n",
    "!{sys.executable} -m pip install --disable-pip-version-check torch torchdata\n",
    "!{sys.executable} -m pip install transformers datasets \\\n",
    "    evaluate loralib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "\n",
    "model_pretrain = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.filter(lambda example, index : index % 500 ==0, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_config = SFTConfig(dataset_text_field=\"text\",max_seq_length=512,output_dir=\"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model_pretrain,\n",
    "    train_dataset=dataset,\n",
    "    args=sft_config,\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sauvegarde le modèle qu'on vient d'entraîner\n",
    "trainer.save_model('./opt_post_imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fine_tune=AutoModelForCausalLM.from_pretrained(\"./opt_post_imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accéder aux probas du token suivant en utilisant model()\n",
    "inputs = tokenizer(\"Today is a\", return_tensors=\"pt\")\n",
    "output=model_pretrain(**inputs)\n",
    "next_token_logits = output.logits[0, -1, :]\n",
    "print(next_token_logits.shape)\n",
    "print(next_token_logits)\n",
    "print(torch.softmax(next_token_logits, -1))\n",
    "next_token_probs = torch.topk(torch.softmax(next_token_logits, -1),5)\n",
    "print(*[(tokenizer.decode(idx), prob) for idx, prob in zip(next_token_probs.indices, next_token_probs.values)], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accéder aux probas des tokens suivants en utilisant model.generate\n",
    "output_generate=model_pretrain.generate(**inputs,max_new_tokens=5, return_dict_in_generate=True, output_scores=True)\n",
    "transition_scores = model_pretrain.compute_transition_scores(\n",
    "    output_generate.sequences, output_generate.scores, normalize_logits=True\n",
    ")\n",
    "\n",
    "input_length = 1 if model_pretrain.config.is_encoder_decoder else inputs.input_ids.shape[1]\n",
    "\n",
    "generated_tokens = output_generate.sequences[:, input_length:]\n",
    "\n",
    "for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "\n",
    "    # | token | token string | log probability | probability\n",
    "\n",
    "    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accéder aux probas des tokens suivants en utilisant model.generate\n",
    "output_generate=model_fine_tune.generate(**inputs,max_new_tokens=5, return_dict_in_generate=True, output_scores=True)\n",
    "transition_scores = model_fine_tune.compute_transition_scores(\n",
    "    output_generate.sequences, output_generate.scores, normalize_logits=True\n",
    ")\n",
    "\n",
    "input_length = 1 if model_fine_tune.config.is_encoder_decoder else inputs.input_ids.shape[1]\n",
    "\n",
    "generated_tokens = output_generate.sequences[:, input_length:]\n",
    "\n",
    "for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "\n",
    "    # | token | token string | log probability | probability\n",
    "\n",
    "    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accéder aux poids des modèles sous forme de liste\n",
    "print(model_pretrain.named_parameters)\n",
    "parametres_pretrain = [(nom, param.data) for nom, param in model_pretrain.named_parameters()]\n",
    "parametres_fine_tune = [(nom, param.data) for nom, param in model_fine_tune.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accéder au nom et aux poids d'une couche du modèle\n",
    "print(parametres_pretrain[2][0])\n",
    "print(parametres_pretrain[2][1][1 :3, 0 :2])\n",
    "print(parametres_fine_tune[2][1][1 :3, 0 :2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
