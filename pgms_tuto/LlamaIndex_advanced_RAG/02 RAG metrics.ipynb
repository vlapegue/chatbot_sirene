{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39468d8b-8ca9-4137-b2b2-53cb57fe8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lesson 2: RAG Triad of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa23a5-6d92-4f49-9de4-1c7a7e2f791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0745a-6db8-4e0a-938d-6532ea66920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba870386-9683-4c9c-af5e-e61048d4b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tru object\n",
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "# La database servira à stocker les prompts, docs retrieved et réponses, pour l'évaluation\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6250b-6771-4f25-8c29-f38b3a8f5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef361f6-7820-4b57-b4f8-a75d4b98d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".\\\n",
    "                    join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014d242-28a5-4734-a59b-086996adc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682687d-d7cd-4cb3-98b0-4f1165c6a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = \\\n",
    "get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1599c4a-1f10-4ef9-ad51-480795a45a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sentence_window_engine.query(\n",
    "    \"How do you create your AI portfolio?\")\n",
    "output.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ec86e-4a0f-4a88-95bf-e4a3bfad3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a43a6-92c6-45b8-9d6c-59a7a9afc32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On installe un streamlit dans le notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8c93d-d97e-4302-9165-b95baebcff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import OpenAI as fOpenAI\n",
    "# provider = le LLM qu'on va utiliser pour évaluer la qualité de la réponse (on peut aussi utiliser un Bert model, pas forcément un LLM)\n",
    "provider = fOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65bb4e-09d5-4411-893a-db85601cabb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Answer Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381aef4-497c-441c-98d2-9a86b229066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Feedback\n",
    "# cot = chain of thought reasoning\n",
    "f_qa_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons,\n",
    "    name=\"Answer Relevance\"\n",
    ").on_input_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57919139-8d9e-4377-b1fc-b6416ce2a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Context Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568da088-3243-4a18-813e-2bffd0b68bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruLlama\n",
    "\n",
    "context_selection = TruLlama.select_source_nodes().node.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102c8ae-e857-4446-a29f-115ea391d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Pour context relevance, on applique \"qs_relevance\" au LLM chargé de l'évaluation\n",
    "# Au lieu de on_output, on charge le contexte, et on fait la moyenne des documents proposés par retrieval\n",
    "f_qs_relevance = (\n",
    "    Feedback(provider.qs_relevance,\n",
    "             name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e125eb-67fb-467f-bd8a-d45f3b1903d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# cot reasons pour avoir un commentaire sur la pertinence du contexte\n",
    "f_qs_relevance = (\n",
    "    Feedback(provider.qs_relevance_with_cot_reasons,\n",
    "             name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f498753-6acb-4363-8e6c-4c9619b7c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. Groundedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69548fa6-ece4-4bad-b2c6-8bc4ad90b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1c0ad-dc3f-4eb6-b893-ff8eff872e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons,\n",
    "             name=\"Groundedness\"\n",
    "            )\n",
    "    .on(context_selection)\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65d4f6-3fa0-47ef-9d25-6a1b56f8420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation of the RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74bebd3-c873-48ca-9ec7-3e40adf04546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trulens propose d'autres métriques : ROUGE, BLEU, Toxicity, Conciseness, etc.\n",
    "from trulens_eval import TruLlama\n",
    "from trulens_eval import FeedbackMode\n",
    "# Recording les questions et réponses en vue d'une évaluation\n",
    "tru_recorder = TruLlama(\n",
    "    sentence_window_engine,\n",
    "    app_id=\"App_1\",\n",
    "    feedbacks=[\n",
    "        f_qa_relevance,\n",
    "        f_qs_relevance,\n",
    "        f_groundedness\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d77a01-638e-4801-93db-55ab14594195",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b3314-d18a-40c8-8bcf-ffea4418ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d70efd-0251-46a5-853a-af9545ececf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions.append(\"How can I be successful in AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fb3f7-ee33-42e0-9b96-eaa80024dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0e6d5-00fe-405d-b38c-cf33630bdbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        sentence_window_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa2f40-799d-44fd-a7c0-18d8ed05533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour voir les logs\n",
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c688c79-e8ad-4403-b070-c41538c23e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne conserve que les input, output et métriques\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1163b-e48c-4f91-aec4-3b3f2963dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ef288-a18b-42c0-94a6-90d8ce5bb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f04df-3689-41a1-9346-cf718a931455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e86523-05b1-4bcf-a87c-9f9d14bd4d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5784cf9-0de9-4401-ab19-60dd85305d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
