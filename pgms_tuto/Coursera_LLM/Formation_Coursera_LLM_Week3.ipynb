{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bae84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuner FLAN-T5 avec PEFT et RLHF (PPO) --> output moins toxiques\n",
    "# On veut diminuer les contenus haineux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73501e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Set up Kernel and required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa25d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69714e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\v\\anaconda3\\lib\\site-packages (23.3)\n",
      "Collecting pip\n",
      "  Downloading pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\v\\anaconda3\\lib\\site-packages (68.2.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\v\\anaconda3\\lib\\site-packages (0.41.2)\n",
      "Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.1 MB 262.6 kB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.1/2.1 MB 656.4 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.2/2.1 MB 958.4 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/2.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/2.1 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.7/2.1 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.9/2.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3\n",
      "    Uninstalling pip-23.3:\n",
      "      Successfully uninstalled pip-23.3\n",
      "Successfully installed pip-23.3.1\n",
      "Requirement already satisfied: torch in c:\\users\\v\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchdata in c:\\users\\v\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\v\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\v\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\v\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\v\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\v\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\v\\anaconda3\\lib\\site-packages (from torchdata) (1.26.16)\n",
      "Requirement already satisfied: requests in c:\\users\\v\\anaconda3\\lib\\site-packages (from torchdata) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\v\\anaconda3\\lib\\site-packages (from requests->torchdata) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\v\\anaconda3\\lib\\site-packages (from requests->torchdata) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\v\\anaconda3\\lib\\site-packages (from requests->torchdata) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\v\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers==4.27.2 in c:\\users\\v\\anaconda3\\lib\\site-packages (4.27.2)\n",
      "Requirement already satisfied: datasets==2.11.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: evaluate==0.4.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: rouge_score==0.1.2 in c:\\users\\v\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: loralib==0.1.1 in c:\\users\\v\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: peft==0.3.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Collecting trl==0.4.4\n",
      "  Downloading trl-0.4.4-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\v\\anaconda3\\lib\\site-packages (from transformers==4.27.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from transformers==4.27.2) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\v\\anaconda3\\lib\\site-packages (from transformers==4.27.2) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from transformers==4.27.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\v\\anaconda3\\lib\\site-packages (from transformers==4.27.2) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\v\\anaconda3\\lib\\site-packages (from transformers==4.27.2) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\v\\anaconda3\\lib\\site-packages (from transformers==4.27.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\v\\anaconda3\\lib\\site-packages (from transformers==4.27.2) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\v\\anaconda3\\lib\\site-packages (from transformers==4.27.2) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from datasets==2.11.0) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from datasets==2.11.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\v\\anaconda3\\lib\\site-packages (from datasets==2.11.0) (2.0.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\v\\anaconda3\\lib\\site-packages (from datasets==2.11.0) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\v\\anaconda3\\lib\\site-packages (from datasets==2.11.0) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in c:\\users\\v\\anaconda3\\lib\\site-packages (from fsspec[http]>=2021.11.1->datasets==2.11.0) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\v\\anaconda3\\lib\\site-packages (from datasets==2.11.0) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\v\\anaconda3\\lib\\site-packages (from datasets==2.11.0) (0.13.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\v\\anaconda3\\lib\\site-packages (from rouge_score==0.1.2) (2.0.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\v\\anaconda3\\lib\\site-packages (from rouge_score==0.1.2) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from rouge_score==0.1.2) (1.16.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\v\\anaconda3\\lib\\site-packages (from peft==0.3.0) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from peft==0.3.0) (2.0.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\v\\anaconda3\\lib\\site-packages (from peft==0.3.0) (0.23.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.11.0) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.11.0) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\v\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.11.0) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\v\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.11.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.11.0) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\v\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.11.0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\v\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.11.0) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\v\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.2) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\v\\anaconda3\\lib\\site-packages (from requests->transformers==4.27.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\v\\anaconda3\\lib\\site-packages (from requests->transformers==4.27.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\v\\anaconda3\\lib\\site-packages (from requests->transformers==4.27.2) (2023.7.22)\n",
      "Requirement already satisfied: sympy in c:\\users\\v\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.3.0) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\v\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.3.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\v\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.3.0) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\v\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.27.2) (0.4.6)\n",
      "Requirement already satisfied: click in c:\\users\\v\\anaconda3\\lib\\site-packages (from nltk->rouge_score==0.1.2) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\v\\anaconda3\\lib\\site-packages (from nltk->rouge_score==0.1.2) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\v\\anaconda3\\lib\\site-packages (from pandas->datasets==2.11.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\v\\anaconda3\\lib\\site-packages (from pandas->datasets==2.11.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\v\\anaconda3\\lib\\site-packages (from pandas->datasets==2.11.0) (2023.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\v\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft==0.3.0) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\v\\anaconda3\\lib\\site-packages (from sympy->torch>=1.13.0->peft==0.3.0) (1.3.0)\n",
      "Downloading trl-0.4.4-py3-none-any.whl (68 kB)\n",
      "   ---------------------------------------- 0.0/68.4 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/68.4 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 41.0/68.4 kB 487.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 61.4/68.4 kB 656.4 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 61.4/68.4 kB 656.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 68.4/68.4 kB 286.6 kB/s eta 0:00:00\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.4.4\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip setuptools wheel\n",
    "#!{sys.executable} -m pip install --disable-pip-version-check torch==1.13.1 torchdata==0.5.1\n",
    "!{sys.executable} -m pip install --disable-pip-version-check torch torchdata\n",
    "!{sys.executable} -m pip install transformers==4.27.2 datasets==2.11.0 \\\n",
    "    evaluate==0.4.0 rouge_score==0.1.2 loralib==0.1.1 peft==0.3.0 trl==0.4.4\n",
    "# Le dernier module est nouveau par rapport à Week2, pour faire de la PPO\n",
    "# Cette dernière library suit l'architecture habituelle de HuggingFace : Trainer et training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bba8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des composants nécessaires\n",
    "from datasets import load_dataset\n",
    "# AutoModelForSeq2SeqLM pour accéder à FLAN-T5\n",
    "# AutoModelForSequenceClassification pour charger un modèle de classification binaire des messages (haineux ou non)\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl = transformers reinforcement learning library\n",
    "from trl import PPOConfig, PPOTrainer, AutoModelForSeq2SeqLMWithValueHead, create_reference_model\n",
    "# LengthSampler au cas où les inputs sont plus longs que la fenêtre d'input\n",
    "from trl.core import LengthSampler\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pour voir joliment la progression des calculs\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Load FLAN-T5 model, prepare Reward model et toxicity evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f81a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Load data et FLAN-T5 model fine-tuned with summarization instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41d5f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/V/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-cd36827d3490488d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06e4690477d4972ab1a26d4370270cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name='google/flan-t5-small'\n",
    "huggingface_dataset_name=\"knkarthick/dialogsum\"\n",
    "dataset_original=load_dataset(huggingface_dataset_name)\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beae8301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/V/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-cd36827d3490488d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a634463228a44ad7988561ff51440d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\V\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\V\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dc88ae32b54d97940e6ae58fa6d9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ab14bec33245bda9cd6084e2819317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c273f6723c884d3886b91b1d199740c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 2736\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 685\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# On crée une fonction build_dataset pour mettre en forme les données en une seule commande\n",
    "# On ne prend qu'une partie des données, on ne prend que celles d'une certaine longueur, \n",
    "# on structure les prompts (instruction, dialogue) et on les tokenise\n",
    "# On sauvegarde les token_ids (input_ids) et les prompts décodés (query)\n",
    "\n",
    "def build_dataset(model_name, dataset_name, input_min_text_length,input_max_text_length):\n",
    "    # Load dataset (seule la partie train est utile dans cet exercice)\n",
    "    dataset=load_dataset(dataset_name, split='train')\n",
    "    # Filtre sur la longueur des dialogues\n",
    "    dataset=dataset.filter(lambda x: len(x['dialogue']) > input_min_text_length and len(x['dialogue']) <= input_max_text_length,batched=False)\n",
    "    # Importer le tokenizer (le même que celui du modèle choisi !)\n",
    "    tokenizer=AutoTokenizer.from_pretrained(model_name, device_map='auto')\n",
    "    \n",
    "    def tokenize(sample):\n",
    "        prompt=f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample['input_ids']=tokenizer.encode(prompt)\n",
    "        # Il faut absolument appeler \"query\" la version décodée du prompt structuré, car c'est la variable d'appel de PPO\n",
    "        sample['query']=tokenizer.decode(sample['input_ids'])\n",
    "        return sample\n",
    "    \n",
    "    # Tokenisation de chaque dialogue du dataset\n",
    "    dataset=dataset.map(tokenize,batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "    \n",
    "    # Split the dataset into train and test parts\n",
    "    dataset_splits=dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "    \n",
    "    return dataset_splits\n",
    "\n",
    "dataset=build_dataset(model_name=model_name, dataset_name=huggingface_dataset_name, input_min_text_length=200,input_max_text_length=500)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34fc3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée une fonction pour montrer les différents paramètres du modèles, en particulier les trainables\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params=0\n",
    "    all_model_params=0\n",
    "    for _,param in model.named_parameters():\n",
    "        all_model_params+=param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params+=param.numel()\n",
    "    return f\"trainable model parameters : {trainable_model_params} \\nall model parameters : {all_model_params} \\npercentage of trainable model parameters : {trainable_model_params/all_model_params}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17cfe16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters : 247577856 \n",
      "all model parameters : 247577856 \n",
      "percentage of trainable model parameters : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd06319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les adapters de LoRA estimés en week2 et on les fusionne avec le modèle original\n",
    "# C'est ce modèle avec adapters qui sera entraîné par RLHF (d'où \"is_trainable=True\" ci-dessous)\n",
    "\n",
    "lora_config=LoraConfig(r=32,lora_alpha=32,target_modules=[\"q\",\"v\"],\n",
    "                      lora_dropout=0.05, bias=\"none\",task_type=TaskType.SEQ2SEQLM)\n",
    "\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "\n",
    "peft_model=PeftModel.from_pretrained(model,'./peft-dialogue-summary-checkpoint/',\n",
    "                                    lora_config=lora_config, torch_dtype=torch.bfloat16,\n",
    "                                    device_map=\"auto\",is_trainable=True)\n",
    "\n",
    "print(f'PEFT Model parameters to be updated : \\n{print_number_of_trainable_model_parameters(peft_model)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e3fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prépare le modèle avec PPO\n",
    "ppo_model=AutoModelForSeq2SeqLMWithValueHead(peft_model, torch_dtype=torch.bfloat16,is_trainable=True)\n",
    "print(f'PPO model parameters to be updated (ValueHead + 769 parameters) : {print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model.v_head)\n",
    "# Il y a 768 dimensions pour le ValueHaead, plus le terme de biais\n",
    "# Le nombre de paramètres qui seront mis à jour (=ValueHead) est égal à (n+1)*m où n=nombre d'inputs (ici 768)\n",
    "# et m=nombre d'outputs (ici 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On stocke le modèle avant detoxification comme référence, pour le calcul de la divergence KL\n",
    "reference_model=create_reference_model(ppo_model)\n",
    "print(f'Reference model parameters to be updated : {print_number_of_trainable_model_parameters(reference_model)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730fba4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b629ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Prepare reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise un reward model sur étagère, qui donne un niveau de haine (logit)\n",
    "# hate =1, not_hate=0\n",
    "toxicity_model_name='facebook/roberta-hate-speech-dynabench-r4-target'\n",
    "toxicity_tokenizer=AutoTokenizer.from_pretrained(toxicity_model_name, device_map='auto')\n",
    "toxicity_model=AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map='auto'))\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application à un simple texte\n",
    "non_toxic_text=\"I want to kiss you\"\n",
    "toxicity_input_ids=toxicity_tokenizer(non_toxic_text,return_tensors='pt').input_ids\n",
    "\n",
    "logits=toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "print(f'Logits [not hate, hate] de la phrase {non_toxic_text}:\\n {logits.tolist()[0]}')\n",
    "\n",
    "probas=logits.softmax(dim=-1).tolist[0]\n",
    "print(f'Probas [not hate, hate] de la phrase {non_toxic_text}:\\n {probas}')\n",
    "\n",
    "# Reward = not hate logit\n",
    "not_hate_index=0\n",
    "not_hate_reward=(logits[:,not_hate_index]).tolist()\n",
    "print(f'Reward: {not_hate_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ef92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application à un autre texte\n",
    "toxic_text=\"You are disgusting and terrible and I damn hate you\"\n",
    "toxicity_input_ids=toxicity_tokenizer(toxic_text,return_tensors='pt').input_ids\n",
    "\n",
    "logits=toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "print(f'Logits [not hate, hate] de la phrase {toxic_text}:\\n {logits.tolist()[0]}')\n",
    "\n",
    "probas=logits.softmax(dim=-1).tolist[0]\n",
    "print(f'Probas [not hate, hate] de la phrase {toxic_text}:\\n {probas}')\n",
    "\n",
    "# Reward = not hate logit\n",
    "not_hate_index=0\n",
    "not_hate_reward=(logits[:,not_hate_index]).tolist()\n",
    "print(f'Reward: {not_hate_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35474893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelques définitions utilisant le pipeline de HuggingFace pour simplifier le code du reward model\n",
    "# Plus besoin d'utiliser model.generate ou tokenizer, \n",
    "# c'est déjà dans le pipeline \"sentiment-analysis\" qui est un classificateur binaire de textes\n",
    "\n",
    "device=0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sentiment_pipe=pipeline(\"sentiment-analysis\",model=toxicity_model_name,device=device)\n",
    "\n",
    "# top_k=None pour avoir tout le monde, function_to_apply=None pour récupérer les logits sans transformation\n",
    "reward_logits_kwargs={\"top_k\": None, \"function_to_apply\": None, \"batch_size\"=16}\n",
    "reward_probas_kwargs={\"top_k\": None, \"function_to_apply\": \"softmax\", \"batch_size\"=16}\n",
    "\n",
    "print(\"Reward model output for non-toxic text : \")\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probas_kwargs))\n",
    "print(\"Reward model output for toxic text : \")\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probas_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb9a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Evaluate toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit une métrique de toxicité comprise entre 0 et 1 : on prend les probas associées aux logits du modèle précédent\n",
    "\n",
    "toxicity_evaluator=evaluate.load(\"toxicity\", toxicity_model_name, module_type=\"measurement\",toxic_label='hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculs de métrique de toxicité\n",
    "\n",
    "toxicity_score=toxicity_evaluator.compute(predictions=[non_toxic_text])\n",
    "\n",
    "print(f'Toxicity score for non_toxic_text {non_toxic_text}')\n",
    "print(toxicity_score['toxicity'])\n",
    "\n",
    "toxicity_score=toxicity_evaluator.compute(predictions=[toxic_text])\n",
    "\n",
    "print(f'\\nToxicity score for toxic_text {toxic_text}')\n",
    "print(toxicity_score['toxicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On rassemble dans une fonction evaluate_toxicity les étapes suivantes : passer en revue le dataset de test,\n",
    "# utiliser le bon tokenizer, charger le PEFT model et le toxicity evaluator\n",
    "# Permet d'avaluer la toxicité moyenne d'un ensemble d'outputs (ici des résumés de dialogues)\n",
    "\n",
    "def evaluate_toxicity(model, toxicity_evaluator, tokenizer, dataset, num_samples):\n",
    "    max_nex_tokens=100\n",
    "    \n",
    "    toxicities=[]\n",
    "    input_texts=[]\n",
    "    for i,sample in tqdm(enumerate(dataset)):\n",
    "        input_text=sample[\"query\"]\n",
    "        if i>num_samples:\n",
    "            break\n",
    "        \n",
    "        input_ids=tokenizer(input_text, return_tensors='pt',padding=True).input_ids\n",
    "        generation_config=GenerationConfig(max_new_tokens=max_new_tokens,tok_k=0.0, tok_p=1.0,do_sample=True)\n",
    "        response_token_ids=model.generate(input_ids=input_ids,generation_config=generation_config)\n",
    "        \n",
    "        generated_text=tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        toxicity_score=toxicity_evaluator.compute(predictions=[(input_text+\" \"+generated_text)])\n",
    "        \n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "        \n",
    "        # On calcule des stats de toxicité\n",
    "        mean=np.mean(toxicities)\n",
    "        std=np.std(toxicities)\n",
    "        \n",
    "        return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule ici le niveau de toxicité du modèle avant detoxification\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name,device_map='auto')\n",
    "\n",
    "mean_before_detoxification,std_before_detoxification=evaluate_toxicity(model=ref_model,toxicity_evaluator=toxicity_evaluator\n",
    "                                                                      tokenizer=tokenizer, dataset=dataset['test'],\n",
    "                                                                      num_samples=10)\n",
    "\n",
    "print(f'Moyenne et écart-type de la toxicité avant détoxification : [{mean_before_detoxification},{std_before_detoxification}]')\n",
    "# Rq sur la performance : le lab de AWS le fait en 25 secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c1306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71119ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Fine-tuning pour diminuer la toxicité des outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Initialiser PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de paramètres de PPO\n",
    "\n",
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=1\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "config=PPOConfig(model_name=model_name,learning_rate=learning_rate,max_ppo_epochs=max_ppo_epochs,\n",
    "                mini_batch_size=mini_batch_size,batch_size=batch_size)\n",
    "\n",
    "def collator(data):\n",
    "    return dict((key,[d[key] for d in data] for key in data[0]))\n",
    "\n",
    "# Exemple d'utilisation de collator\n",
    "test_data=[{\"key1\":\"value1\",\"key2\":\"value2\",\"key3\":\"value3\"}]\n",
    "print(f'Collator input : {test_data}')\n",
    "print(f'Collator output : {collator(test_data)}')\n",
    "\n",
    "ppo_trainer=PPOTrainer(config=config,model=ppo_model,ref_model=ref_model,\n",
    "                       tokenizer=tokenizer,dataset=dataset['train'],data_collator=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701fd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Fine-tune le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b72a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réalise un grand nombre de fois les trois étapes suivantes :\n",
    "# on récupère les réponses du LLM\n",
    "# on calcule les rewards\n",
    "# on optimise la règle PPO en fonction des infos ci-dessus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38723268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette cellule dure 20 à 30 minutes dans le lab de AWS\n",
    "\n",
    "output_min_length=100\n",
    "output_max_length=400\n",
    "\n",
    "output_length_sampler=LengthSampler(output_min_length,output_max_length)\n",
    "\n",
    "generation_kwargs={\"min_length\":0.5,\"top_k\":0.0,\"top_p\":1.0,\"do_sample\":True}\n",
    "\n",
    "reward_kwargs={\"top_k\":None,\"function_to_supply\":None, \"batch_size\":16}\n",
    "\n",
    "max_ppo_steps=10\n",
    "\n",
    "# Pour chaque dialogue du dataset, le modèle fournit une réponse, on calcule le reward du prompt+réponse\n",
    "\n",
    "for step,batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    if step>=max_ppo_steps:\n",
    "        break\n",
    "    \n",
    "    prompt_tensors=batch['input_ids']\n",
    "    \n",
    "    #Réponse de FLan-T5 avec PEFT\n",
    "    summary_tensors=[]\n",
    "    \n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens=output_length_sampler\n",
    "        generation_kwargs[\"max_new_tokens\"]=max_new_tokens\n",
    "        summary=ppo_trainer.generate(prompt_tensor,**generation_kwargs)\n",
    "        \n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "        \n",
    "    # Il faut utiliser le terme \"response\" pour que ce soit reconnu par l'optimiseur\n",
    "    batch[\"response\"]=[tokenizer.decode((r.squeeze()) for r in summary_tensors)\n",
    "                       \n",
    "    # Calcul des rewards\n",
    "    query_response_pairs=[q+r for q,r in zip(batch[\"query\"],batch[\"response\"])]\n",
    "    rewards=sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "    reward_tensors=[torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]\n",
    "    \n",
    "    # Étape PPO (en n'entraînant que les paramètres PEFT/LoRA)\n",
    "    stats=ppo_trainer.step(prompt_tensors, summary_tensors,reward_tensors)\n",
    "    ppo_trainer.log_stats(stats,batch,reward_tensors)\n",
    "                       \n",
    "    print(f'objective/kl : {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean : {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean : {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Evaluate the model quantitatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6475916",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_after_detoxification,std_after_detoxification=evaluate_toxicity(model=ppo_model,toxicity_evaluator=toxicity_evaluator\n",
    "                                                                      tokenizer=tokenizer, dataset=dataset['test'],\n",
    "                                                                      num_samples=10)\n",
    "\n",
    "print(f'Moyenne et écart-type de la toxicité après détoxification : [{mean_after_detoxification},{std_after_detoxification}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec83457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Evaluate the Model qualitatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4103e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde à la main quelques exemples\n",
    "\n",
    "batch_size=20\n",
    "compare_results={}\n",
    "df_batch=dataset['test'][0:batch_size]\n",
    "\n",
    "compare_results[\"query\"]=df_batch['query']\n",
    "prompt_tensors=df_batch['input_ids']\n",
    "\n",
    "summary_tensors_ref=[]\n",
    "summary_tensors=[]\n",
    "\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len=output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"]=gen_len\n",
    "    \n",
    "    summary=ref_model.generate(input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "                              **generation_kwargs).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "    \n",
    "    summary=ppo_model.generate(input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "                              **generation_kwargs).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "    \n",
    "# On décode les réponses\n",
    "compare_results[\"response_before\"]=[tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"]=[tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# Calcul des rewards sur les paires query+response\n",
    "texts_before=[d+s for d,s in zip(compare_results[\"query\"],compare_results[\"response_before\"])]\n",
    "rewards_before=sentiment_pipe(texts_before,**reward_kwargs)\n",
    "compare_results[\"reward_before\"]=[reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "\n",
    "texts_after=[d+s for d,s in zip(compare_results[\"query\"],compare_results[\"response_after\"])]\n",
    "rewards_after=sentiment_pipe(texts_after,**reward_kwargs)\n",
    "compare_results[\"reward_after\"]=[reward[not_hate_index][\"score\"] for reward in rewards_after]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',500)\n",
    "df_compare_results=pd.DataFrame(compare_results)\n",
    "df_compare_results[\"reward_diff\"]=df_compare_results[\"reward_after\"]-df_compare_results[\"reward_before\"]\n",
    "df_compare_results_sorted=df_compare_results.sort_values(by=['reward_diff'],ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d3a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b32b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48854dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42671cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344c6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13eb92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06fe08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb88798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e6e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0bc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca191c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf745bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
